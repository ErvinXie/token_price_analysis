#!/usr/bin/env python3
"""
LLM TokenæœåŠ¡æ”¶ç›Šè®¡ç®—å™¨
è®¡ç®—å•æœåŠ¡æ”¶ç›Šã€ç¡¬ä»¶å¹¶å‘èƒ½åŠ›ï¼Œä»¥åŠç”Ÿå‘½å‘¨æœŸæ€»æ”¶ç›Š
æ¨¡å‹å®šä»·å’ŒæœåŠ¡æ€§èƒ½è§£è€¦
"""

from dataclasses import dataclass
from typing import Dict, List, Tuple
import json
from database import TokenServiceDatabase, HardwareConfig, SLALevel


@dataclass
class ModelPricing:
    """æ¨¡å‹å®šä»·é…ç½®"""
    model_name: str        # æ¨¡å‹åç§°
    input_price_per_m: float    # è¾“å…¥tokenä»·æ ¼ï¼ˆå…ƒ/M tokensï¼‰
    output_price_per_m: float   # è¾“å‡ºtokenä»·æ ¼ï¼ˆå…ƒ/M tokensï¼‰

    def calculate_request_revenue(self, input_tokens: int, output_tokens: int) -> float:
        """è®¡ç®—å•æ¬¡è¯·æ±‚çš„æ”¶ç›Š"""
        input_cost = (input_tokens / 1_000_000) * self.input_price_per_m
        output_cost = (output_tokens / 1_000_000) * self.output_price_per_m
        return input_cost + output_cost


@dataclass
class ServiceProfile:
    """å•ä¸ªæœåŠ¡çš„é…ç½®ï¼ˆæœåŠ¡è´¨é‡ï¼‰"""
    input_tokens: int      # å¹³å‡è¾“å…¥tokenæ•°
    output_tokens: int     # å¹³å‡è¾“å‡ºtokenæ•°
    prefill_tps: float     # æœåŠ¡prefillæ€§èƒ½ (tokens/sec)
    decode_tps: float      # æœåŠ¡decodeæ€§èƒ½ (tokens/sec)


@dataclass
class HardwarePerformance:
    """ç¡¬ä»¶æ€§èƒ½é…ç½® - åªå…³å¿ƒå¹¶å‘èƒ½åŠ›"""
    hardware_name: str              # ç¡¬ä»¶åç§°ï¼ˆå…³è”æ•°æ®åº“ï¼‰
    max_concurrent_requests: int    # æœ€å¤§å¹¶å‘è¯·æ±‚æ•°
    cost_mode: str = "rental"       # æˆæœ¬æ¨¡å¼: "rental" æˆ– "purchase"
    gpu_count: int = 1              # GPUæ•°é‡
    power_consumption_w: int = 0    # åŠŸè€—ï¼ˆç“¦ç‰¹ï¼‰


@dataclass
class ServiceParameters:
    """æœåŠ¡è¿è¡Œå‚æ•°"""
    lifecycle_years: int          # ç”Ÿå‘½å‘¨æœŸï¼ˆå¹´ï¼‰
    average_load_factor: float    # å¹³å‡è´Ÿè½½ç³»æ•°ï¼ˆ0-1ï¼‰
    uptime_percentage: float      # å¯ç”¨æ€§ï¼ˆ0-1ï¼‰
    sla_level: str = "standard"   # SLAç­‰çº§


def load_model_prices_from_db() -> Dict[str, ModelPricing]:
    """ä»SQLiteæ•°æ®åº“åŠ è½½æ¨¡å‹ä»·æ ¼"""
    db = TokenServiceDatabase()
    return db.get_model_pricing()


class TokenServiceCalculator:
    """TokenæœåŠ¡æ”¶ç›Šè®¡ç®—å™¨"""

    def __init__(self):
        self.model_pricing = None
        self.service_profile = None
        self.hardware = None
        self.service_params = None
        self.db = TokenServiceDatabase()  # åˆå§‹åŒ–æ•°æ®åº“è¿æ¥

    def set_model_pricing(self, model_pricing: ModelPricing):
        """è®¾ç½®æ¨¡å‹å®šä»·"""
        self.model_pricing = model_pricing

    def set_model_from_catalog(self, model_key: str, category_filter: str = None):
        """ä»æ•°æ®åº“ä¸­é€‰æ‹©æ¨¡å‹"""
        try:
            db = TokenServiceDatabase()
            if category_filter:
                # æŒ‰ç±»åˆ«è¿‡æ»¤
                models = db.get_models_by_category(category_filter)
                catalog = {model.model_key: model for model in models}
            else:
                catalog = db.get_model_pricing()
        except Exception as e:
            raise FileNotFoundError(f"æ— æ³•åŠ è½½ä»·æ ¼æ•°æ®: {e}\nè¯·å…ˆè¿è¡Œ: python migrate_data.py")

        if model_key not in catalog:
            available_models = list(catalog.keys())
            raise ValueError(f"æ¨¡å‹ '{model_key}' ä¸å­˜åœ¨ï¼Œå¯ç”¨æ¨¡å‹: {available_models[:10]}...")

        # è½¬æ¢æ•°æ®åº“ModelPricingåˆ°è®¡ç®—å™¨ModelPricing
        db_model = catalog[model_key]
        self.model_pricing = ModelPricing(
            model_name=db_model.model_name,
            input_price_per_m=db_model.input_price_per_m,
            output_price_per_m=db_model.output_price_per_m
        )

    def list_available_models(self, category_filter: str = None) -> List[str]:
        """åˆ—å‡ºå¯ç”¨çš„æ¨¡å‹"""
        try:
            db = TokenServiceDatabase()
            if category_filter:
                models = db.get_models_by_category(category_filter)
            else:
                catalog = db.get_model_pricing()
                models = list(catalog.values())
        except Exception as e:
            raise FileNotFoundError(f"æ— æ³•åŠ è½½ä»·æ ¼æ•°æ®: {e}\nè¯·å…ˆè¿è¡Œ: python migrate_data.py")

        # è¿”å›æ¨¡å‹keyåˆ—è¡¨
        return [model.model_key for model in models]

    def set_service_profile(self, service_profile: ServiceProfile):
        self.service_profile = service_profile

    def set_hardware(self, hardware: HardwarePerformance):
        self.hardware = hardware

    def set_service_parameters(self, params: ServiceParameters):
        self.service_params = params

    def calculate_single_service_metrics(self) -> Dict:
        """è®¡ç®—å•ä¸ªæœåŠ¡çš„åŸºç¡€æŒ‡æ ‡"""
        # å•æ¬¡è¯·æ±‚æ”¶ç›Š
        revenue_per_request = self.model_pricing.calculate_request_revenue(
            self.service_profile.input_tokens,
            self.service_profile.output_tokens
        )

        # å•æ¬¡è¯·æ±‚å¤„ç†æ—¶é—´ï¼ˆåŸºäºæœåŠ¡è´¨é‡å‚æ•°ï¼‰
        prefill_time = self.service_profile.input_tokens / self.service_profile.prefill_tps
        decode_time = self.service_profile.output_tokens / self.service_profile.decode_tps
        processing_time = prefill_time + decode_time

        # ç†è®ºQPSï¼ˆæ¯ç§’å¤„ç†çš„è¯·æ±‚æ•°ï¼‰
        qps_per_instance = 1 / processing_time if processing_time > 0 else 0

        # æ¯ä¸ªå®ä¾‹æ¯å¤©å¤„ç†çš„è¯·æ±‚æ•°
        daily_requests_per_instance = qps_per_instance * 3600 * 24 * self.service_params.uptime_percentage

        # å•å®ä¾‹æ—¥æ”¶ç›Š
        daily_revenue_per_instance = daily_requests_per_instance * revenue_per_request

        return {
            'revenue_per_request': revenue_per_request,
            'prefill_time': prefill_time,
            'decode_time': decode_time,
            'processing_time': processing_time,
            'qps_per_instance': qps_per_instance,
            'daily_requests_per_instance': daily_requests_per_instance,
            'daily_revenue_per_instance': daily_revenue_per_instance
        }

    def calculate_hardware_capacity(self) -> Dict:
        """è®¡ç®—ç¡¬ä»¶çš„æ€»æœåŠ¡èƒ½åŠ›"""
        # è·å–åŸºäºSLAçš„æœ‰æ•ˆå¹¶å‘æ•°
        effective_concurrent_requests = self.get_effective_concurrency()

        return {
            'max_concurrent_requests': effective_concurrent_requests,
            'instances_count': effective_concurrent_requests
        }

    def calculate_hardware_cost(self) -> Dict:
        """è®¡ç®—ç¡¬ä»¶æˆæœ¬ï¼ˆç§Ÿç”¨æ¨¡å¼æˆ–è´­ä¹°æ¨¡å¼ï¼‰"""
        if not self.hardware:
            return {'monthly_cost': 0, 'lifecycle_cost': 0, 'cost_details': {}}

        # ä»æ•°æ®åº“è·å–ç¡¬ä»¶é…ç½®
        hardware_configs = {hw.name: hw for hw in self.db.get_hardware_configs()}

        if self.hardware.hardware_name not in hardware_configs:
            # å¦‚æœæ•°æ®åº“ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨é»˜è®¤è®¡ç®—
            if self.hardware.cost_mode == "rental":
                monthly_cost = 8000  # é»˜è®¤ç§Ÿç”¨æˆæœ¬
            else:
                # è´­ä¹°æ¨¡å¼ï¼šæŠ˜æ—§ + è¿è¥æˆæœ¬
                purchase_cost = 80000  # é»˜è®¤è´­ä¹°æˆæœ¬
                depreciation_years = 5
                monthly_maintenance = 500
                monthly_power_cost = (self.hardware.power_consumption_w * 24 * 30) / 1000 * 0.8  # å‡è®¾ç”µè´¹0.8å…ƒ/åº¦
                monthly_cost = (purchase_cost / depreciation_years / 12) + monthly_maintenance + monthly_power_cost
        else:
            hw_config = hardware_configs[self.hardware.hardware_name]

            if self.hardware.cost_mode == "rental":
                monthly_cost = hw_config.monthly_rental_cost_yuan
            else:
                # è´­ä¹°æ¨¡å¼ï¼šæŠ˜æ—§ + è¿è¥æˆæœ¬
                monthly_depreciation = hw_config.purchase_cost_yuan / hw_config.depreciation_years / 12
                monthly_power_cost = (hw_config.power_consumption_w * 24 * 30) / 1000 * 0.8
                monthly_cost = monthly_depreciation + hw_config.monthly_maintenance_cost_yuan + monthly_power_cost

        lifecycle_cost = monthly_cost * 12 * self.service_params.lifecycle_years

        return {
            'monthly_cost': monthly_cost,
            'lifecycle_cost': lifecycle_cost,
            'cost_details': {
                'mode': self.hardware.cost_mode,
                'hardware_name': self.hardware.hardware_name,
                'gpu_count': self.hardware.gpu_count if hasattr(self.hardware, 'gpu_count') else 1
            }
        }

    def get_effective_concurrency(self) -> int:
        """è·å–åŸºäºSLAå’ŒæœåŠ¡è´¨é‡çš„æœ‰æ•ˆå¹¶å‘æ•°"""
        if not all([self.model_pricing, self.hardware, self.service_params, self.service_profile]):
            return self.hardware.max_concurrent_requests if self.hardware else 0

        # å°è¯•ä»æ•°æ®åº“è·å–ç²¾ç¡®çš„å¹¶å‘å®¹é‡ï¼ˆåŸºäºinput/output tokensï¼‰
        try:
            capacity = self.db.calculate_hardware_capacity(
                self.hardware.hardware_name,
                self._get_model_key_from_pricing(),
                self.service_params.sla_level,
                self.service_profile.input_tokens,
                self.service_profile.output_tokens
            )

            if capacity:
                return capacity['max_concurrent_requests']
        except Exception as e:
            print(f"âš ï¸  ä»æ•°æ®åº“è·å–å¹¶å‘å®¹é‡å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–è®¡ç®—: {e}")

        # ç®€åŒ–è®¡ç®—ï¼šåŸºäºSLAç­‰çº§è°ƒæ•´å¹¶å‘æ•°
        sla_configs = {
            "basic": 1.0,
            "standard": 0.8,
            "premium": 0.6,
            "enterprise": 0.4
        }

        sla_ratio = sla_configs.get(self.service_params.sla_level, 0.8)
        return int(self.hardware.max_concurrent_requests * sla_ratio)

    def _get_model_key_from_pricing(self) -> str:
        """ä»æ¨¡å‹å®šä»·è·å–æ¨¡å‹key"""
        # ä»model_pricing.model_nameç”Ÿæˆkey
        import re
        model_name = self.model_pricing.model_name.lower()
        # æ›¿æ¢æ–œæ å’Œå…¶ä»–å­—ç¬¦
        key = re.sub(r'[^a-z0-9]+', '-', model_name)
        return key.strip('-')

    def calculate_lifecycle_revenue(self) -> Dict:
        """è®¡ç®—ç”Ÿå‘½å‘¨æœŸæ€»æ”¶ç›Š"""
        # å•æœåŠ¡æŒ‡æ ‡ï¼ˆåŒ…å«åŸºäºç¡¬ä»¶çš„å¤„ç†æ—¶é—´ï¼‰
        single_metrics = self.calculate_single_service_metrics()

        # è·å–åŸºäºSLAçš„æœ‰æ•ˆå¹¶å‘æ•°
        effective_concurrent_requests = self.get_effective_concurrency()

        # æ€»QPS = å¹¶å‘æ•° Ã— å•ä¸ªå®ä¾‹çš„QPS
        total_qps = effective_concurrent_requests * single_metrics['qps_per_instance']

        # æœ‰æ•ˆQPSï¼ˆè€ƒè™‘è´Ÿè½½ç³»æ•°ï¼‰
        effective_qps = total_qps * self.service_params.average_load_factor

        # æ¯æ—¥æ€»è¯·æ±‚æ•°
        daily_total_requests = effective_qps * 3600 * 24

        # æ¯æ—¥æ€»æ”¶ç›Š
        daily_total_revenue = daily_total_requests * single_metrics['revenue_per_request']

        # ç”Ÿå‘½å‘¨æœŸæ€»æ”¶ç›Š
        days_in_year = 365
        total_days = self.service_params.lifecycle_years * days_in_year
        lifecycle_revenue = daily_total_revenue * total_days

        # å¹´åŒ–æ”¶ç›Š
        annual_revenue = daily_total_revenue * days_in_year

        # ç¡¬ä»¶æˆæœ¬è®¡ç®—
        hardware_cost = self.calculate_hardware_cost()

        # å‡€æ”¶ç›Šï¼ˆæ”¶ç›Š - æˆæœ¬ï¼‰
        daily_net_revenue = daily_total_revenue - (hardware_cost['monthly_cost'] / 30)
        annual_net_revenue = annual_revenue - hardware_cost['monthly_cost'] * 12
        lifecycle_net_revenue = lifecycle_revenue - hardware_cost['lifecycle_cost']

        return {
            'single_request_revenue': single_metrics['revenue_per_request'],
            'prefill_time': single_metrics['prefill_time'],
            'decode_time': single_metrics['decode_time'],
            'processing_time': single_metrics['processing_time'],
            'qps_per_instance': single_metrics['qps_per_instance'],
            'effective_qps': effective_qps,
            'daily_total_requests': daily_total_requests,
            'daily_revenue': daily_total_revenue,
            'daily_net_revenue': daily_net_revenue,
            'annual_revenue': annual_revenue,
            'annual_net_revenue': annual_net_revenue,
            'lifecycle_revenue': lifecycle_revenue,
            'lifecycle_net_revenue': lifecycle_net_revenue,
            'concurrent_capacity': effective_concurrent_requests,
            'utilization_rate': self.service_params.average_load_factor,
            'hardware_cost': hardware_cost
        }

    def generate_report(self) -> str:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        if not all([self.model_pricing, self.service_profile, self.hardware, self.service_params]):
            return "è¯·è®¾ç½®æ‰€æœ‰å¿…è¦çš„é…ç½®å‚æ•°"

        metrics = self.calculate_lifecycle_revenue()

        return f"""
LLM TokenæœåŠ¡æ”¶ç›Šåˆ†ææŠ¥å‘Š
{'=' * 50}

æœåŠ¡è´¨é‡é…ç½®:
- è¾“å…¥Tokenæ•°: {self.service_profile.input_tokens:,}
- è¾“å‡ºTokenæ•°: {self.service_profile.output_tokens:,}
- è¾“å…¥è¾“å‡ºæ¯”ä¾‹: {self.service_profile.input_tokens/self.service_profile.output_tokens:.2f}
- Pre-fill TPS: {self.service_profile.prefill_tps:,.0f} tokens/sec
- Decode TPS: {self.service_profile.decode_tps:,.0f} tokens/sec

æ¨¡å‹é…ç½®:
- æ¨¡å‹åç§°: {self.model_pricing.model_name}
- è¾“å…¥Token: Â¥{self.model_pricing.input_price_per_m:.2f}/M tokens
- è¾“å‡ºToken: Â¥{self.model_pricing.output_price_per_m:.2f}/M tokens
- å•è¯·æ±‚æ”¶ç›Š: Â¥{metrics['single_request_revenue']:.6f}

ç¡¬ä»¶é…ç½®:
- ç¡¬ä»¶ç±»å‹: {self.hardware.hardware_name}
- GPUæ•°é‡: {self.hardware.gpu_count}
- æˆæœ¬æ¨¡å¼: {self.hardware.cost_mode}
- å£°æ˜æœ€å¤§å¹¶å‘æ•°: {self.hardware.max_concurrent_requests}

å¤„ç†æ€§èƒ½:
- Pre-fillæ—¶é—´: {metrics['prefill_time']:.4f} ç§’
- Decodeæ—¶é—´: {metrics['decode_time']:.4f} ç§’
- å•æ¬¡è¯·æ±‚å¤„ç†æ—¶é—´: {metrics['processing_time']:.4f} ç§’
- å•å®ä¾‹QPS: {metrics['qps_per_instance']:.3f}

æœåŠ¡è¿è¡Œå‚æ•°:
- ç”Ÿå‘½å‘¨æœŸ: {self.service_params.lifecycle_years} å¹´
- å¹³å‡è´Ÿè½½ç³»æ•°: {self.service_params.average_load_factor:.1%}
- æœåŠ¡å¯ç”¨æ€§: {self.service_params.uptime_percentage:.1%}
- SLAç­‰çº§: {self.service_params.sla_level}

æˆæœ¬åˆ†æ:
- ç¡¬ä»¶æœˆæˆæœ¬: Â¥{metrics['hardware_cost']['monthly_cost']:,.2f}
- ç¡¬ä»¶æ€»æˆæœ¬: Â¥{metrics['hardware_cost']['lifecycle_cost']:,.2f}

æ”¶ç›Šåˆ†æ:
- æœ‰æ•ˆå¹¶å‘å®¹é‡: {metrics['concurrent_capacity']} ä¸ªè¯·æ±‚
- æ€»QPS: {metrics['effective_qps']:.1f}
- æ—¥å¤„ç†è¯·æ±‚é‡: {metrics['daily_total_requests']:,.0f}
- æ—¥æ”¶ç›Š: Â¥{metrics['daily_revenue']:,.2f}
- æ—¥å‡€æ”¶ç›Š: Â¥{metrics['daily_net_revenue']:,.2f}
- å¹´æ”¶ç›Š: Â¥{metrics['annual_revenue']:,.2f}
- å¹´å‡€æ”¶ç›Š: Â¥{metrics['annual_net_revenue']:,.2f}
- {self.service_params.lifecycle_years}å¹´æ€»æ”¶ç›Š: Â¥{metrics['lifecycle_revenue']:,.2f}
- {self.service_params.lifecycle_years}å¹´å‡€æ”¶ç›Š: Â¥{metrics['lifecycle_net_revenue']:,.2f}

åˆ©ç”¨ç‡åˆ†æ:
- ç¡¬ä»¶åˆ©ç”¨ç‡: {metrics['utilization_rate']:.1%}
- ç†è®ºå³°å€¼QPS: {metrics['effective_qps'] / metrics['utilization_rate']:.1f}
- åˆ©æ¶¦ç‡: {(metrics['lifecycle_net_revenue'] / metrics['lifecycle_revenue'] * 100):.1f}%
"""


def create_example_calculator(model_key: str = "qwen2-7b") -> TokenServiceCalculator:
    """åˆ›å»ºç¤ºä¾‹è®¡ç®—å™¨"""
    calc = TokenServiceCalculator()

    # è®¾ç½®æ¨¡å‹å®šä»·
    calc.set_model_from_catalog(model_key)

    # æœåŠ¡é…ç½®ï¼ˆæœåŠ¡è´¨é‡ï¼‰
    service_profile = ServiceProfile(
        input_tokens=8000,     # 8kè¾“å…¥tokens
        output_tokens=2000,    # 2kè¾“å‡ºtokens
        prefill_tps=4000,     # 4k prefills/sec (RTX4090x4çš„ç†è®ºå€¼)
        decode_tps=20         # 20 decodes/sec
    )
    calc.set_service_profile(service_profile)

    # ç¡¬ä»¶æ€§èƒ½ï¼ˆåªå…³å¿ƒå¹¶å‘èƒ½åŠ›ï¼ŒTPSå±äºæœåŠ¡è´¨é‡ï¼‰
    hardware = HardwarePerformance(
        hardware_name="8xH20",  # ä½¿ç”¨æ•°æ®åº“ä¸­çš„ç¡¬ä»¶é…ç½®
        max_concurrent_requests=32,  # æœ€å¤§32å¹¶å‘
        cost_mode="rental",    # ç§Ÿç”¨æ¨¡å¼
        gpu_count=8,          # 8ä¸ªGPU
        power_consumption_w=1500  # 1500WåŠŸè€—
    )
    calc.set_hardware(hardware)

    # æœåŠ¡å‚æ•°
    params = ServiceParameters(
        lifecycle_years=3,           # 3å¹´ç”Ÿå‘½å‘¨æœŸ
        average_load_factor=0.3,     # 30%å¹³å‡è´Ÿè½½
        uptime_percentage=0.95,      # 95%å¯ç”¨æ€§
        sla_level="standard"         # æ ‡å‡†SLAç­‰çº§
    )
    calc.set_service_parameters(params)

    return calc




if __name__ == "__main__":
    import sys

    if len(sys.argv) > 1 and sys.argv[1] == "models":
        # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹åˆ—è¡¨
        calc = TokenServiceCalculator()
        try:
            category = sys.argv[2] if len(sys.argv) > 2 else None
            models = calc.list_available_models(category_filter=category)
            print(f"ğŸ“‹ å¯ç”¨æ¨¡å‹åˆ—è¡¨ ({len(models)} ä¸ª):")
            for model in models:
                print(f"  - {model}")
        except Exception as e:
            print(f"âŒ è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")

  
    else:
        # è¿è¡Œç¤ºä¾‹åˆ†æ
        try:
            calculator = create_example_calculator("moonshotai-kimi-k2-thinking")
            print(calculator.generate_report())

            print("\n" + "=" * 60)
            print("ğŸ’¡ ä½¿ç”¨æç¤º:")
            print("  python token_service_calculator.py models [category]  # æ˜¾ç¤ºå¯ç”¨æ¨¡å‹")
            print("  python price_updater.py                              # æ›´æ–°ä»·æ ¼æ•°æ®")

        except FileNotFoundError:
            print("âŒ æœªæ‰¾åˆ°ä»·æ ¼æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œ: python price_updater.py")
        except ValueError as e:
            print(f"âŒ é”™è¯¯: {e}")